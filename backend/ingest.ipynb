{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pinecone-client\n",
    "# %pip install python-dotenv\n",
    "# %pip install openai\n",
    "# %pip install chromadb-client\n",
    "\n",
    "# %pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "# index = pc.Index(\"test-pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "\n",
    "# response = client.embeddings.create(\n",
    "#     input=\"Your text string goes here\",\n",
    "#     model=\"text-embedding-3-large\"\n",
    "# )\n",
    "\n",
    "# print(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version = \"2024-02-01\",\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=\"Your text string goes here\",\n",
    "    model=\"ada_gcal\"\n",
    ")\n",
    "\n",
    "print(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text, model=\"ada_gcal\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# df_bills['ada_v2'] = df_bills[\"text\"].apply(lambda x : generate_embeddings (x, model = 'text-embedding-ada-002'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"./pdf/grokking.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pages))\n",
    "print()\n",
    "\n",
    "full_document = \"\"\n",
    "\n",
    "for page in pages:\n",
    "  full_document += page.page_content\n",
    "\n",
    "print(full_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# first, extract Section Headers\n",
    "pattern = r\"\\n\\d+ [A-Z][a-zA-Z\\s:]+\\n\"\n",
    "\n",
    "# Find all matches\n",
    "matches = re.findall(pattern, full_document)\n",
    "\n",
    "matches.insert(0, \"Abstract\")\n",
    "\n",
    "# Print all section titles\n",
    "for match in matches:\n",
    "    print(match.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\n\\d+ [A-Z][a-zA-Z\\s:]+\\n\"\n",
    "\n",
    "# Split the text into sections\n",
    "sections = re.split(pattern, full_document)\n",
    "\n",
    "# number of sections should match with number of section titles (aka matches of regex pattern)\n",
    "# print(sections[0])\n",
    "# print(sections[2])\n",
    "# print(len(sections))\n",
    "\n",
    "# Create a dictionary to store section titles and contents\n",
    "section_contents = {}\n",
    "\n",
    "# Use zip to iterate over matches and sections simultaneously\n",
    "for match, section in zip(matches, sections):\n",
    "    section_title = match.strip()\n",
    "    content = section.strip()\n",
    "    section_contents[section_title] = content\n",
    "\n",
    "section_contents.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_contents[\"6 Conclusion\"] #TODO: process this to ONLY the abstract content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, content in section_contents.items():\n",
    "    print(title)\n",
    "    print(len(content))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsection = section_contents[\"3 Why Generalization Occurs: Representations and Dynamics\"]\n",
    "subsection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then extract subsections from sections\n",
    "pattern = r\"\\n\\d+\\.\\d+ [A-Z][a-zA-Z\\s:]+\\n\"\n",
    "\n",
    "subsections = re.findall(pattern, subsection)\n",
    "print(len(subsections))\n",
    "for match in subsections:\n",
    "    print(match.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract references from conclusion\n",
    "conclusion = section_contents[\"6 Conclusion\"]\n",
    "section_contents[\"6 Conclusion\"] = conclusion.split(\"References\")[0]\n",
    "# conclusion.split(\"References\")[1]\n",
    "\n",
    "section_contents[\"6 Conclusion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run subsection splitting algo\n",
    "\n",
    "for title, section in section_contents.items():\n",
    "  pattern = r\"\\n\\d+\\.\\d+ [A-Z][a-zA-Z\\s:]+\\n\"\n",
    "  subsections_headers = re.findall(pattern, section)\n",
    "  \n",
    "  if len(subsections_headers) > 0:\n",
    "    subsection_map = {}\n",
    "    subsections_content = re.split(pattern, section)\n",
    "\n",
    "    subsections_headers.insert(0, title)\n",
    "    for subsection_header, subsection in zip(subsections_headers, subsections_content):\n",
    "      subsection_title = subsection_header.strip()\n",
    "      content = subsection.strip()\n",
    "      subsection_map[subsection_title] = content\n",
    "\n",
    "    print(subsection_map.keys())\n",
    "    section_contents[title] = subsection_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(section_contents[\"3 Why Generalization Occurs: Representations and Dynamics\"])\n",
    "len(section_contents[\"4 Delayed Generalization: A Phase Diagram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this for section title-based splitting\n",
    "section_contents[\"4 Delayed Generalization: A Phase Diagram\"]['4.1 Phase diagram of a toy model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text, model=\"ada_gcal\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# df_bills['ada_v2'] = df_bills[\"text\"].apply(lambda x : generate_embeddings (x, model = 'text-embedding-ada-002'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "azure_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "                api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "                api_type=\"azure\",\n",
    "                api_version = \"2024-02-01\",\n",
    "                model_name=\"ada_gcal\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "# Example setup of the client to connect to your chroma server\n",
    "client = chromadb.HttpClient(host='localhost', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.delete_collection(name=\"test_pdf\") \n",
    "# Delete a collection and all associated embeddings, documents, and metadata. ⚠️ This is destructive and not reversible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(\n",
    "        embedding_function=azure_ef,\n",
    "        name=\"test_pdf\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"} # l2 is the default\n",
    "    )\n",
    "collection = client.get_collection(name=\"test_pdf\", embedding_function=azure_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': [],\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'data': None,\n",
       " 'uris': None}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collection.peek() # returns a list of the first 10 items in the collection\n",
    "# collection.count() # returns the number of items in the collection\n",
    "# collection.modify(name=\"new_name\") # Rename the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract\n",
      "Towards Understanding Grokking:\n",
      "An Effective Theory of Representation Learning\n",
      "Ziming Liu, Ouail Kitouni, Niklas Nolte, Eric J. Michaud, Max Tegmark, Mike Williams\n",
      "Department of Physics, Institute for AI and Fundamental Interactions, MIT\n",
      "{zmliu,kitouni,nnolte,ericjm,tegmark,mwill}@mit.edu\n",
      "Abstract\n",
      "We aim to understand grokking , a phenomenon where models generalize long after\n",
      "overﬁtting their training set. We present both a microscopic analysis anchored by an\n",
      "effective theory and a macroscopic analysis of phase diagrams describing learning\n",
      "performance across hyperparameters. We ﬁnd that generalization originates from\n",
      "structured representations whose training dynamics and dependence on training set\n",
      "size can be predicted by our effective theory in a toy setting. We observe empirically\n",
      "the presence of four learning phases: comprehension ,grokking ,memorization , and\n",
      "confusion . We ﬁnd representation learning to occur only in a “Goldilocks zone”\n",
      "(including comprehension and grokking) between memorization and confusion.\n",
      "We ﬁnd on transformers the grokking phase stays closer to the memorization phase\n",
      "(compared to the comprehension phase), leading to delayed generalization. The\n",
      "Goldilocks phase is reminiscent of “intelligence from starvation” in Darwinian\n",
      "evolution, where resource limitations drive discovery of more efﬁcient solutions.\n",
      "This study not only provides intuitive explanations of the origin of grokking, but\n",
      "also highlights the usefulness of physics-inspired tools, e.g., effective theories and\n",
      "phase diagrams, for understanding deep learning.\n",
      "\n",
      "1 Introduction\n",
      "Perhaps thecentral challenge of a scientiﬁc understanding of deep learning lies in accounting for neu-\n",
      "ral network generalization. Power et al. [ 1] recently added a new puzzle to the task of understanding\n",
      "generalization with their discovery of grokking . Grokking refers to the surprising phenomenon of\n",
      "delayed generalization where neural networks, on certain learning problems, generalize long after\n",
      "overﬁtting their training set. It is a rare albeit striking phenomenon that violates common machine\n",
      "learning intuitions, raising three key puzzles:\n",
      "Q1The origin of generalization : When trained on the algorithmic datasets where grokking occurs,\n",
      "how do models generalize at all?\n",
      "Q2The critical training size : Why does the training time needed to “grok” (generalize) diverge as\n",
      "the training set size decreases toward a critical point?\n",
      "Q3Delayed generalization : Under what conditions does delayed generalization occur?\n",
      "We provide evidence that representation learning is central to answering each of these questions. Our\n",
      "answers can be summarized as follows:\n",
      "A1Generalization can be attributed to learning a good representation of the input embeddings,\n",
      "i.e., a representation that has the appropriate structure for the task and which can be predicted\n",
      "from the theory in Section 3. See Figures 1 and 2.\n",
      "A2The critical training set size corresponds to the least amount of training data that can determine\n",
      "such a representation (which, in some cases, is unique up to linear transformations).\n",
      "36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2205.10343v2  [cs.LG]  14 Oct 2022Initialization (0 iterations)\n",
      "train acc: 0.0 — val acc: 0.0Overﬁtting (1000 iterations)\n",
      "train acc: 1.0 — val acc: 0.1Representation Learning (20000 iterations)\n",
      "train acc: 1.0 — val acc: 1.0Figure 1: Visualization of the ﬁrst two principal components of the learned input embeddings at\n",
      "different training stages of a transformer learning modular addition. We observe that generalization\n",
      "coincides with the emergence of structure in the embeddings. See Section 4.2 for the training details.\n",
      "A3Grokking is a phase between “comprehension” and “memorization” phases and it can be\n",
      "remedied with proper hyperparmeter tuning, as illustrated by the phase diagrams in Figure 6.\n",
      "This paper is organized as follows: In Section 2, we introduce the problem setting and build a\n",
      "simpliﬁed toy model. In Section 3, we will use an effective theory approach, a useful tool from\n",
      "theoretical physics, to shed some light on questions Q1andQ2and show the relationship between\n",
      "generalization and the learning of structured representations. In Section 4, we explain Q3by\n",
      "displaying phase diagrams from a grid search of hyperparameters and show how we can “de-delay”\n",
      "generalization by following intuition developed from the phase diagram. We discuss related work in\n",
      "Section 5, followed by conclusions in Section 6.1\n",
      "\n",
      "2 Problem Setting\n",
      "Power et al. [ 1] observe grokking on a less common task – learning “algorithmic” binary operations.\n",
      "Given some binary operation ◦, a network is tasked with learning the map (a,b)↦→cwherec=a◦b.\n",
      "They use a decoder-only transformer to predict the second to last token in a tokenized equation of the\n",
      "form “<lhs> <op> <rhs> <eq> <result> <eos>”. Each token is represented as a 256-dimensional\n",
      "embedding vector. The embeddings are learnable and initialized randomly. After the transformer, a\n",
      "ﬁnal linear layer maps the output to class logits for each token.\n",
      "Toy Model We primarily study grokking in a simpler toy model, which still retains the key behaviors\n",
      "from the setup of [ 1]. Although [ 1] treated this as a classiﬁcation task, we study both regression\n",
      "(mean-squared error) and classiﬁcation (cross-entropy). The basic setup is as follows: our model\n",
      "takes as input the symbols a,band maps them to trainable embedding vectors Ea,Eb∈Rdin. It\n",
      "then sums Ea,Eband sends the resulting vector through a “decoder” MLP. The target output vector,\n",
      "denoted Yc∈Rdoutis a ﬁxed random vector (regression task) or a one-hot vector (classiﬁcation\n",
      "task). Our model architecture can therefore be compactly described as (a,b)↦→Dec(Ea+Eb),\n",
      "where the embeddings E∗and the decoder are trainable. Despite its simplicity, this toy model can\n",
      "generalize to all abelian groups (discussed in Appendix B). In sections 3-4.1, we consider only the\n",
      "binary operation of addition. We consider modular addition in Section 4.2 to generalize some of our\n",
      "results to a transformer architecture and study general non-abelian operations in Appendix H.\n",
      "Dataset In our toy setting, we are concerned with learning the addition operation. A data sample\n",
      "corresponding to i+jis denoted as (i,j)for simplicity. If i,j∈{0,...,p−1}, there are in total\n",
      "p(p+ 1)/2different samples since we consider i+jandj+ito be the same sample. A dataset D\n",
      "is a set of non-repeating data samples. We denote the full dataset as D0and split it into a training\n",
      "datasetDand a validation dataset D′, i.e.,D⋃D′=D0,D⋂D′=∅. We deﬁne training data\n",
      "fraction =|D|/|D0|where|·|denotes the cardinality of the set.\n",
      "1Project code can be found at: https://github.com/ejmichaud/grokking-squared\n",
      "2RQI: 0.0 — Accuracy - train: 1.0, validation: 0.1\n",
      "02468101214161820(a) Memorization in toy addition\n",
      "RQI: 0.6 — Accuracy - train: 1.0, validation: 0.9\n",
      "02468101214161820 (b) Generalization in toy addition\n",
      "Accuracy - train: 1.0, validation: 0.1\n",
      "0246810\n",
      "(c) Memorization in toy modular addition\n",
      "Accuracy - train: 1.0, validation: 0.9\n",
      "0246810 (d) Generalization in toy modular addition\n",
      "Figure 2: Visualization of the learned set of embeddings ( p= 11 ) and the decoder function associated\n",
      "with it for the case of 2D embeddings. Axes refer to each dimension of the learned embeddings. The\n",
      "decoder is evaluated on a grid of points in embedding-space and the color at each point represents\n",
      "the highest probability class. For visualization purposes, the decoder is trained on inputs of the form\n",
      "(Ei+Ej)/2. One can read off the output of the decoder when fed the operation i◦jfrom this ﬁgure\n",
      "simply by taking the midpoint between the respective embeddings of iandj.\n",
      "\n",
      "3 Why Generalization Occurs: Representations and Dynamics\n",
      "{'3 Why Generalization Occurs: Representations and Dynamics': 'We can see that generalization appears to be linked to the emergence of highly-structured embeddings\\nin Figure 2. In particular, Figure 2 (a, b) shows parallelograms in toy addition, and (c, d) shows a\\ncircle in toy modular addition. We now restrict ourselves to the toy addition setup and formalize a\\nnotion of representation quality and show that it predicts the model’s performance. We then develop a\\nphysics-inspired effective theory of learning which can accurately predict the critical training set size\\nand training trajectories of representations. The concept of an effective theory in physics is similar\\nto model reduction in computational methods in that it aims to describe complex phenomena with\\nsimple yet intuitive pictures. In our effective theory, we will model the dynamics of representation\\nlearning not as gradient descent of the true task loss but rather a simpler effective loss function ℓeff\\nwhich depends only on the representations in embedding space and not on the decoder.', '3.1 Representation quality predicts generalization for the toy model': 'A rigorous deﬁnition for structure in the learned representation is necessary. We propose the following\\ndeﬁnition,\\nDeﬁnition 1. (i,j,m,n )is aδ-parallelogram in the representation R≡[E0,···,Ep−1]if\\n|(Ei+Ej)−(Em+En)|≤δ.\\nIn the following derivations, we can take δ, which is a small threshold to tolerate numerical errors, to\\nbe zero.\\nProposition 1. When the training loss is zero, any parallelogram (i,j,m,n )in representation R\\nsatisﬁesi+j=m+n.\\nProof. Suppose that this is not the case, i.e., suppose Ei+Ej=Em+Enbuti+j̸=m+n, then\\nYi+j= Dec( Ei+Ej) = Dec( Em+En) =Ym+nwhere the ﬁrst and last equalities come from\\nthe zero training loss assumption. However, since i+j̸=m+n, we have Yi+j̸=Yn+m(almost\\nsurely in the regression task), a contradiction.\\n30.0 0.2 0.4 0.6 0.8 1.0\\ntraining data fraction0.00.20.40.60.81.0Acc\\nMemorization(a)\\n0.0 0.2 0.4 0.6 0.8 1.0\\ntraining set fraction0.00.20.40.60.81.0ˆAcc(b)\\n0.0 0.2 0.4 0.6 0.8 1.0\\nˆAcc0.00.20.40.60.81.0Acc(c)Figure 3: We compute accuracy (of the full dataset) either measured empirically Acc, or predicted\\nfrom the representation of the embeddings ˆAcc. These two accuracies as a function of training data\\nfraction are plotted in (a)(b), and their agreement is shown in (c).\\nIt is convenient to deﬁne the permissible parallelogram set associated with a training dataset D\\n(“permissible” means consistent with 100% training accuracy) as\\nP0(D) ={(i,j,m,n )|(i,j)∈D,(m,n)∈D, i+j=m+n}. (1)\\nFor simplicity, we denote P0≡P0(D0). Given a representation R, we can check how many\\npermissible parallelograms actually exist in Rwithin error δ, so we deﬁne the parallelogram set\\ncorresponding to Ras\\nP(R,δ) ={(i,j,m,n )|(i,j,m,n )∈P0,|(Ei+Ej)−(Em+En)|≤δ}. (2)\\nFor brevity we will write P(R), suppressing the dependence on δ. We deﬁne the representation\\nquality index (RQI) as\\nRQI(R) =|P(R)|\\n|P0|∈[0,1]. (3)\\nWe will use the term linear representation orlinear structure to refer to a representation whose\\nembeddings are of the form Ek=a+kb(k= 0,···,p−1;a,b∈Rdin). A linear representation\\nhasRQI = 1 , while a random representation (sampled from, say, a normal dstribution) has RQI = 0\\nwith high probability.\\nQuantitatively, we denote the “predicted accuracy” ˆAcc as the accuracy achievable on the whole\\ndataset given the representation R(see Appendix D for the full details). In Figure 3, we see that\\nthe predictedˆAcc aligns well with the true accuracy Acc, establishing good evidence that structured\\nrepresentation of input embeddings leads to generalization. We use an example to illustrate the origin\\nof generalization here. In the setup of Figure 2 (b), suppose the decoder can achieve zero training\\nloss and E6+E8is a training sample hence Dec(E6+E8) =Y14. At validation time, the decoder\\nis tasked with predicting a validation sample E5+E9. Since (5,9,6,8)forms a parallelogram\\nsuch that E5+E9=E6+E8, the decoder can predict the validation sample correctly because\\nDec(E5+E9) = Dec( E6+E8) =Y14.', '3.2 The dynamics of embedding vectors': 'Suppose that we have an ideal model M∗= (Dec∗,R∗)such that:2\\n• (1)M∗can achieve zero training loss;\\n• (2)M∗has an injective decoder, i.e., Dec∗(x1)̸= Dec∗(x2)for any x1̸=x2.\\nThen Proposition 2 provides a mechanism for the formation of parallelograms.\\n2One can verify a posteriori if a trained model Mis close to being an ideal model M∗. Please refer to\\nAppendix E for details.\\n40.00.20.40.60.81.0\\ntraining data fraction0.00.20.40.60.81.0Probability(linear structure) rc= 0.4(a) Theory: phase transition\\n0.4 0.6 0.8 1.0\\ntraining data fraction102103104Steps to RQI >0.95\\nrc= 0.4(b) Empirical: phase transition\\nRuns that reached\\nRQI>0.95 in 104steps\\nRuns that didn’t reach\\nRQI>0.95 in 104steps\\n0 500 1000 1500 2000\\nstep−1.5−1.0−0.50.00.51.01.51D representation\\n0123456789\\n3nh(c) Theory: trajectory\\n0 500 1000 1500 2000\\nstep−1.5−1.0−0.50.00.51.01.51D normalized representation 0123456789\\n3nh(d) Empirical: trajectoryFigure 4: (a) The effective theory predicts a phase transition in the probability of obtaining a linear\\nrepresentation around rc= 0.4. (b) Empirical results display a phase transition of RQI around\\nrc= 0.4, in agreement with the theory (the blue line shows the median of multiple random seeds).\\nThe evolution of 1D representations predicted by the effective theory or obtained from neural network\\ntraining (shown in (c) and (d) respectively) agree creditably well.\\nProposition 2. If a training set Dcontains two samples (i,j)and(m,n)withi+j=m+n,\\nthenM∗learns a representation R∗such that Ei+Ej=Em+En, i.e., (i,j,m,n )forms a\\nparallelogram.\\nProof. Due to the zero training loss assumption, we have Dec∗(Ei+Ej) =Yi+j=Ym+n=\\nDec∗(Em+En). Then the injectivity of Dec∗implies Ei+Ej=Em+En.\\nThe dynamics of the trained embedding vectors are determined by various factors interacting in\\ncomplex ways, for instance: the details of the decoder architecture, the optimizer hyperparameters,\\nand the various kinds of implicit regularization induced by the training procedure. We will see that\\nthe dynamics of normalized quantities, namely, the normalized embeddings at time t, deﬁned as\\n˜E(t)\\nk=E(t)\\nk−µt\\nσt, whereµt=1\\np∑\\nkE(t)\\nkandσt=1\\np∑\\nk|E(t)\\nk−µt|2, can be qualitatively described\\nby a simple effective loss (in the physics effective theory sense). We will assume that the normalized\\nembedding vectors obey a gradient ﬂow for an effective loss function of the form\\nd˜Ei\\ndt=−∂ℓeff\\n∂˜Ei, (4)\\nℓeff=ℓ0\\nZ0, ℓ 0≡∑\\n(i,j,m,n )∈P0(D)|˜Ei+˜Ej−˜Em−˜En|2/|P0(D)|, Z 0≡∑\\nk|˜Ek|2, (5)\\nwhere|·|denotes Euclidean vector norm. Note that the embeddings do not collapse to the trivial\\nsolution E0=···=Ep−1= 0unless initialized as such, because two conserved quantities exist, as\\nproven in Appendix F:\\nC=∑\\nkEk, Z 0=∑\\nk|Ek|2. (6)\\nWe shall now use the effective dynamics to explain empirical observations such as the existence of a\\ncritical training set size for generalization.\\nDegeneracy of ground states (loss optima) We deﬁne ground states as those representations satis-\\nfyingℓeff= 0, which requires the following linear equations to hold:\\nA(P) ={Ei+Ej=Em+En|(i,j,m,n )∈P}. (7)\\nSince each embedding dimension obeys the same set of linear equations, we will assume, without loss\\nof generality, that din= 1. The dimension of the null space of A(P), denoted as n0, is the number of\\ndegrees of freedom of the ground states. Given a set of parallelograms implied by a training dataset\\nD, the nullity of A(P(D))could be obtained by computing the singular values 0≤σ1≤···≤σp.\\nWe always have n0≥2, i.e.,σ1=σ2= 0because the nullity of A(P0), the set of linear equations\\ngiven by all possible parallelograms, is Nullity(A(P0)) = 2 which can be attributed to two degrees\\n5of freedom (translation and scaling). If n0= 2, the representation is unique up to translations and\\nscaling factors, and the embeddings have the form Ek=a+kb. Otherwise, when n0>2, the\\nrepresentation is not constrained enough such that all the embeddings lie on a line.\\nWe present theoretical predictions alongside empirical results for addition ( p= 10 ) in Figure 4. As\\nshown in Figure 4 (a), our effective theory predicts that the probability that the training set implies a\\nunique linear structure (which would result in perfect generalization) depends on the training data\\nfraction and has a phase transition around rc= 0.4. Empirical results from training different models\\nare shown in Figure 4 (b). The number of steps to reach RQI>0.95is seen to have a phase transition\\natrc= 0.4, agreeing with the proposed effective theory and with the empirical ﬁndings in [1].\\nTime towards the linear structure We deﬁne the Hessian matrix of ℓ0as\\nHij=1\\nZ0∂2ℓ0\\n∂Ei∂Ej, (8)\\nNote thatℓeﬀ=1\\n2RTHR,R= [E0,E1,···,Ep−1], so the gradient descent is linear, i.e.,\\ndR\\ndt=−HR. (9)\\nIfHhas eigenvalues λi=σ2\\ni(sorted in increasing order) and eigenvectors ¯vi, and we have the initial\\ncondition R(t= 0) =∑\\niai¯vi, then we have R(t) =∑\\niai¯vie−λit. The ﬁrst two eigenvalues\\nvanish andth= 1/λ3determines the timescale for the slowest component to decrease by a factor\\nofe. We callλ3thegrokking rate . When the step size is η, the corresponding number of steps is\\nnh=th/η= 1/(λ3η).\\nWe verify the above analysis with empirical results. Figure 4 (c)(d) show the trajectories obtained\\nfrom the effective theory and from neural network training, respectively. The 1D neural representation\\nin Figure 4 (d) are manually normalized to zero mean and unit variance. The two trajectories agree\\nqualitatively, and it takes about 3nhsteps for two trajectories to converge to the linear structure. The\\nquantitative differences might be due to the absence of the decoder in the effective theory, which\\nassumes the decoder to take inﬁnitesimal step sizes.\\nDependence of grokking on data size Note thatℓeﬀinvolves averaging over parallelograms in the\\ntraining set, it is dependent on training data size, so is λ3. In Figure 5 (a), we plot the dependence of\\nλ3on training data fraction. There are many datasets with the same data size, so λ3is a probabilistic\\nfunction of data size.\\nTwo insights on grokking can be extracted from this plot: (i) When the data fraction is below some\\nthreshold (around 0.4), λ3is zero with high probability, corresponding to no generalization. This\\nagain veriﬁes our critical point in Figure 4. (ii) When data size is above the threshold, λ3(on average)\\nis an increasing function of data size. This implies that grokking time t∼1/λ3decreases as training\\ndata size becomes larger, an important observation from [1].\\nTo verify our effective theory, we compare the grokking steps obtained from real neural network\\ntraining (deﬁned as steps to RQI>0.95), and those predicted by our theory tth∼1\\nλ3η(ηis the\\nembedding learning rate), shown in Figure 5 (b). The theory agrees qualitatively with neural networks,\\nshowing the trend of decreasing grokking steps as increasing data size. The quantitative differences\\nmight be explained as the gap between our effective loss and actual loss.\\nLimitations of the effective theory While our theory deﬁnes an effective loss based on the Euclidean\\ndistance between embeddings Ei+EjandEn+Em, one could imagine generalizing the theory to\\ndeﬁne a broader notion of parallogram given by some other metric on the representation space. For\\ninstance, if we have a decoder like in Figure 2 (d) then the distance between distinct representations\\nwithin the same “pizza slice” is low, meaning that representations arranged not in parallelograms\\nw.r.t. the Euclidean metric may be parallelograms with respect to the metric deﬁned by the decoder.\\n4 Delayed Generalization: A Phase Diagramw.r.t. the Euclidean metric may be parallelograms with respect to the metric deﬁned by the decoder.'}\n",
      "\n",
      "4 Delayed Generalization: A Phase Diagram\n",
      "{'4 Delayed Generalization: A Phase Diagram': 'So far, we have (1) observed empirically that generalization on algorithmic datasets corresponds with\\nthe emergence of well-structured representations, (2) deﬁned a notion of representation quality in a\\ntoy setting and shown that it predicts generalization, and (3) developed an effective theory to describe\\n60.0 0.2 0.4 0.6 0.8 1.0\\ntraining data fraction0.00.10.20.30.4grokking rate λ3(a)\\n10−210−1100\\ngrokking rate λ3103104Steps to RQI >0.95tth= 1\\n/(2λ3η)\\nRuns that didn’t reach RQI >0.95 in 104steps\\nRuns that reached RQI >0.95 in 104steps (b)\\nFigure 5: Effective theory explains the dependence of grokking time on data size, for the addition\\ntask. (a) Dependence of λ3on training data fraction. Above the critical data fraction (around 0.4),\\nas data size becomes larger, λ3increases hence grokking time t∼1/λ3(predicted by our effective\\ntheory) decreases. (b) Comparing grokking steps (deﬁned as RQI>0.95) predicted by the effective\\ntheory with real neural network results. η= 10−3is the learning rate of the embeddings.\\nthe learning dynamics of the representations in the same toy setting. We now study how optimizer\\nhyperparameters affect high-level learning performance. In particular, we develop phase diagrams for\\nhow learning performance depends on the representation learning rate, decoder learning rate and the\\ndecoder weight decay. These parameters are of interest since they most explicitly regulate a kind of\\ncompetition between the encoder and decoder, as we elaborate below.', '4.1 Phase diagram of a toy model': 'Training details We update the representation and the decoder with different optimizers. For the\\n1D embeddings, we use the Adam optimizer with learning rate [10−5,10−2]and zero weight decay.\\nFor the decoder, we use an AdamW optimizer with the learning rate in [10−5,10−2]and the weight\\ndecay in [0,10](regression) or [0,20](classiﬁcation). For training/validation spliting, we choose\\n45/10 for non-modular addition ( p= 10 ) and 24/12 for the permutation group S3. We hard-code\\naddition or matrix multiplication (details in Appendix H) in the decoder for the addition group and\\nthe permutation group, respectively.\\nFor each choice of learning rate and weight decay, we compute the number of steps to reach high\\n(90%) training/validation accuracy. The 2D plane is split into four phases: comprehension ,grokking ,\\nmemorization andconfusion , deﬁned in Table 1 in Appendix A. Both comprehension and grokking are\\nable to generalize (in the “Goldilocks zone”), although the grokking phase has delayed generalization.\\nMemorization is also called overﬁtting, and confusion means failure to even memorize training data.\\nFigure 6 shows the phase diagrams for the addition group and the permutation group. They display\\nquite rich phenomena.\\nCompetition between representation learning and decoder overﬁtting In the regression setup of\\nthe addition dataset, we show how the competition between representation learning and decoder\\nlearning (which depend on both learning rate and weight decay, among other things) lead to different\\nlearning phases in Figure 6 (a). As expected, a fast decoder coupled with slow representation learning\\n(bottom right) lead to memorization. In the opposite extreme, although an extremely slow decoder\\ncoupled with fast representation learning (top left) will generalize in the end, the generalization time is\\nlong due to the inefﬁcient decoder training. The ideal phase (comprehension) requires representation\\nlearning to be faster, but not too much, than the decoder.\\nDrawing from an analogy to physical systems, one can think of embedding vectors as a group of\\nparticles. In our effective theory from Section 3.2, the dynamics of the particles are described only\\nby their relative positions, in that sense, structure forms mainly due to inter-particle interactions (in\\nreality, these interactions are mediated by the decoder and the loss). The decoder plays the role of an\\nenvironment exerting external forces on the embeddings. If the magnitude of the external forces are\\nsmall/large one can expect better/worse representations.\\n71e-5 1e-4 1e-3 1e-2\\ndecoder learning rate1e-2\\n1e-3\\n1e-4\\n1e-5representation learning ratecomprehension\\nmemorizationgrokking(a) Addition, regression\\n1e-5 1e-4 1e-3 1e-2\\ndecoder learning rate0\\n5\\n10 weight decay\\ncomprehensionmemorization\\ngrokking\\nconfusion (b) Addition, regression\\n1e-5 1e-4 1e-3 1e-2\\ndecoder learning rate0\\n10\\n20 weight decaycomprehensionmemorization\\ngrokking\\nconfusion\\n(c) Addition, classiﬁcation\\n1e-5 1e-4 1e-3 1e-2\\ndecoder learning rate0\\n10\\n200 weight decaycomprehensionmemorization\\ngrokking\\nconfusion (d) Permutation, regression\\nFigure 6: Phase diagrams of learning for the addition group and the permutation group. (a) shows the\\ncompetition between representation and decoder. (b)(c)(d): each phase diagram contains four phases:\\ncomprehension, grokking, memorization and confusion, deﬁned in Table 1. In (b)(c)(d), grokking is\\nsandwiched between comprehension and memorization.\\nUniversality of phase diagrams We ﬁx the embedding learning rate to be 10−3and sweep instead\\ndecoder weight decay in Figure 6 (b)(c)(d). The phase diagrams correspond to addition regression (b),\\naddition classiﬁcation (c) and permutation regression (d), respectively. Common phenomena emerge\\nfrom these different tasks: (i) they all include four phases; (ii) The top right corner (a fast and capable\\ndecoder) is the memorization phase; (iii) the bottom right corner (a fast and simple decoder) is the\\nconfusion phase; (iv) grokking is sandwiched between comprehension and memorization, which\\nseems to imply that it is an undesirable phase that stems from improperly tuned hyperparameters.', '4.2 Beyond the toy model\\nWe conjecture that many of the principles which we saw dictate the training dynamics in the toy': 'model also apply more generally. Below, we will see how our framework generalizes to transformer\\narchitectures for the task of addition modulo p, a minimal reproducible example of the original\\ngrokking paper [1].\\nWe ﬁrst encode p= 53 integers into 256D learnable embeddings, then pass two integers to a decoder-\\nonly transformer architecture. For simplicity, we do not encode the operation symbols here. The\\noutputs from the last layer are concatenated and passed to a linear layer for classiﬁcation. Training\\nboth the encoder and the decoder with the same optimizer (i.e., with the same hyperparameters)\\nleads to the grokking phenomenon. Generalization appears much earlier once we lower the effective\\ndecoder capacity with weight decay (full phase diagram in Figure 7).\\nEarly on, the model is able to perfectly ﬁt the training set while having no generalization. We study\\nthe embeddings at different training times and ﬁnd that neither PCA (shown in Figure 1) nor t-SNE\\n(not shown here) reveal any structure. Eventually, validation accuracy starts to increase, and perfect\\ngeneralization coincides with the PCA projecting the embeddings into a circle in 2D. Of course, no\\n8100102104\\nstep303540455055eﬀective dimension eS\\neS\\ngeneralization\\nmemorization\\n0.0 0.2 0.4\\ndropout rate101103105epochs to 90% accuracyvalidation\\ntrain\\nvalidation - train\\n3e-7 1e-4 4e-2\\nlearning rate1e-2\\n2e-1\\n2e+0\\n3e+1weight decay\\ncomprehensionmemorization\\ngrokking\\nconfusionFigure 7: Left: Evolution of the effective dimension of the embeddings (deﬁned as the exponential of\\nthe entropy) during training and evaluated over 100 seeds. Center: Effect of dropout on speeding up\\ngeneralization. Right: Phase diagram of the transformer architecture. A scan is performed over the\\nweight decay and learning rate of the decoder while the learning rate of the embeddings is kept ﬁxed\\nat10−3(with zero weight decay).\\nchoice of dimensionality reduction is guaranteed to ﬁnd any structure, and thus, it is challenging\\nto show explicitly that generalization only occurs when a structure exists. Nevertheless, the fact\\nthat, when coupled with the implicit regularization of the optimizer for sparse solutions, such a clear\\nstructure appears in a simple PCA so quickly at generalization time suggests that our analysis in\\nthe toy setting is applicable here as well. This is also seen in the evolution of the entropy of the\\nexplained variance ratio in the PCA of the embeddings (deﬁned as S=−∑\\niσilogσiwhereσiis\\nthe fractional variance explained by the ith principal component). As seen in Figure 7, the entropy\\nincreases up to generalization time then decreases drastically afterwards which would be consistent\\nwith the conjecture that generalization occurs when a low-dimensional structure is discovered. The\\ndecoder then primarily relies on the information in this low-dimensional manifold and essentially\\n“prunes” the rest of the high-dimensional embedding space. Another interesting insight appears when\\nwe project the embeddings at initialization onto the principal axes at the end of training. Some of the\\nstructure required for generalization exists before training hinting at a connection with the Lottery\\nTicket Hypothesis. See Appendix K for more details.\\nIn Figure 7 (right), we show a comparable phase diagram to Figure 6 evaluated now in the transformer\\nsetting. Note that, as opposed to the setting in [ 1], weight decay has only been applied to the decoder\\nand not to the embedding layer. Contrary to the toy model, a certain amount of weight decay proves\\nbeneﬁcial to generalization and speeds it up signiﬁcantly. We conjecture that this difference comes\\nfrom the different embedding dimensions. With a highly over-parameterized setting, a non-zero\\nweight decay gives a crucial incentive to reduce complexity in the decoder and help generalize in\\nfewer steps. This is subject to further investigation. We also explore the effect of dropout layers\\nin the decoder blocks of the transformer. With a signiﬁcant dropout rate, the generalization time\\ncan be brought down to under 103steps and the grokking phenomenon vanishes completely. The\\noverall trend suggests that constraining the decoder with the same tools used to avoid overﬁtting\\nreduces generalization time and can avoid the grokking phenomenon. This is also observed in an\\nimage classiﬁcation task where we were able to induce grokking. See Appendix J for more details.', '4.3 Grokking Experiment on MNIST': 'We now demonstrate, for the ﬁrst time, that grokking (signiﬁcantly delayed generalization) is a more\\ngeneral phenomenon in machine learning that can occur not only on algorithmic datasets, but also\\non mainstream benchmark datasets. In particular, we exhibit grokking on MNIST in Figure 8 and\\ndemonstrate that we can control grokking by varying optimization hyperparameters. More details on\\nthe experimental setup are in Appendix J.'}\n",
      "\n",
      "5 Related work\n",
      "Relatively few works have analyzed the phenomenon of grokking. [ 2] describe the circuit that\n",
      "transformers use to perform modular addition, track its formation over training, and broadly suggest\n",
      "that grokking is related to the phenomenon of “phase changes” in neural network training. [ 3,4]\n",
      "9102103104105\n",
      "Optimization Steps0.20.40.60.81.0AccuracyTrain Points: 1000 | Initialization Scale: 9.0\n",
      "train\n",
      "val(a)\n",
      "1.00e-06 2.98e-05 8.86e-04 2.64e-02 7.85e-01\n",
      "Last Layer Learning Rate1.00e-05\n",
      "2.98e-04\n",
      "8.86e-03\n",
      "2.64e-01\n",
      "7.85e+00Weight DecayMemorization\n",
      "Grokking\n",
      "Comprehension\n",
      "Confusion (b)\n",
      "Figure 8: Left: Training curves for a run on MNIST, in the setting where we observe grokking. Right:\n",
      "Phase diagram with the four phases of learning dynamics on MNIST.\n",
      "provided earlier speculative, informal conjectures on grokking [ 3,4]. Our work is related to the\n",
      "following broad research directions:\n",
      "Learning mathematical structures [5] trains a neural network to learn arithmetic operation from\n",
      "pictures of digits, but they do not observe grokking due to their abundant training data. Beyond\n",
      "arithmetic relations, machine learning has been applied to learn other mathematical structures,\n",
      "including geometry [6], knot theory [7] and group theory [8].\n",
      "Double descent Grokking is somewhat reminiscent of the phenomena of “epoch-wise” double\n",
      "descent [9], where generalization can improve after a period of overﬁtting. [ 10] ﬁnd that regularization\n",
      "can mitigate double descent, similar perhaps to how weight decay inﬂuences grokking.\n",
      "Representation learning Representation learning lies at the core of machine learning [ 11–14].\n",
      "Representation quality is usually measured by (perhaps vague) semantic meanings or performance on\n",
      "downstream tasks. In our study, the simplicity of arithmetic datasets allows us to deﬁne representation\n",
      "quality and study evolution of representations in a quantitative way.\n",
      "Physics of learning Physics-inspired tools have proved to be useful in understanding deep learning\n",
      "from a theoretical perspective. These tools include effective theories [ 15,16], conservation laws [ 17]\n",
      "and free energy principle [ 18]. In addition, statistical physics has been identiﬁed as a powerful tool in\n",
      "studying generalization in neural networks [ 19–22]. Our work connects a low-level understanding of\n",
      "models with their high-level performance. In a recent work, researchers at Anthropic [ 23], connect a\n",
      "sudden decrease in loss during training with the emergence of induction heads within their models.\n",
      "They analogize their work to statistical physics , since it bridges a “microscopic”, mechanistic\n",
      "understanding of networks with “macroscopic” facts about overall model performance.\n",
      "\n",
      "6 Conclusion\n",
      "We have shown how, in both toy models and general settings, that representation enables generalization\n",
      "when it reﬂects structure in the data. We developed an effective theory of representation learning\n",
      "dynamics (in a toy setting) which predicts the critical dependence of learning on the training data\n",
      "fraction. We then presented four learning phases (comprehension, grokking, memorization and\n",
      "confusion) which depend on the decoder capacity and learning speed (given by, among other things,\n",
      "learning rate and weight decay) in decoder-only architectures. While we have mostly focused on a\n",
      "toy model, we ﬁnd preliminary evidence that our results generalize to the setting of [1].\n",
      "Our work can be viewed as a step towards a statistical physics of deep learning , connecting the\n",
      "“microphysics” of low-level network dynamics with the “thermodynamics” of high-level model\n",
      "behavior. We view the application of theoretical tools from physics, such as effective theories [ 24], to\n",
      "be a rich area for further work. The broader impact of such work, if successful, could be to make\n",
      "models more transparent and predictable [ 23,25,26], crucial to the task of ensuring the safety of\n",
      "advanced AI systems.\n",
      "10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# collection.add(\n",
    "#     documents=[\"lorem ipsum...\", \"doc2\", \"doc3\", ...],\n",
    "#     metadatas=[{\"chapter\": \"3\", \"verse\": \"16\"}, {\"chapter\": \"3\", \"verse\": \"5\"}, {\"chapter\": \"29\", \"verse\": \"11\"}, ...],\n",
    "#     ids=[\"id1\", \"id2\", \"id3\", ...]\n",
    "# )\n",
    "\n",
    "for title, content in section_contents.items():\n",
    "  print(title)\n",
    "  print(content)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
