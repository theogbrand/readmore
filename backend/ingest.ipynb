{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pinecone-client\n",
    "# %pip install python-dotenv\n",
    "# %pip install openai\n",
    "# %pip install chromadb-client\n",
    "\n",
    "# %pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "# index = pc.Index(\"test-pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "\n",
    "# response = client.embeddings.create(\n",
    "#     input=\"Your text string goes here\",\n",
    "#     model=\"text-embedding-3-large\"\n",
    "# )\n",
    "\n",
    "# print(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version = \"2024-02-01\",\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=\"Your text string goes here\",\n",
    "    model=\"ada_gcal\"\n",
    ")\n",
    "\n",
    "print(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text, model=\"ada_gcal\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# df_bills['ada_v2'] = df_bills[\"text\"].apply(lambda x : generate_embeddings (x, model = 'text-embedding-ada-002'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"./pdf/grokking.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pages))\n",
    "print()\n",
    "\n",
    "full_document = \"\"\n",
    "\n",
    "for page in pages:\n",
    "  full_document += page.page_content\n",
    "\n",
    "print(full_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# first, extract Section Headers\n",
    "pattern = r\"\\n\\d+ [A-Z][a-zA-Z\\s:]+\\n\"\n",
    "\n",
    "# Find all matches\n",
    "matches = re.findall(pattern, full_document)\n",
    "\n",
    "matches.insert(0, \"Abstract\")\n",
    "\n",
    "# Print all section titles\n",
    "for match in matches:\n",
    "    print(match.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\n\\d+ [A-Z][a-zA-Z\\s:]+\\n\"\n",
    "\n",
    "# Split the text into sections\n",
    "sections = re.split(pattern, full_document)\n",
    "\n",
    "# number of sections should match with number of section titles (aka matches of regex pattern)\n",
    "# print(sections[0])\n",
    "# print(sections[2])\n",
    "# print(len(sections))\n",
    "\n",
    "# Create a dictionary to store section titles and contents\n",
    "section_contents = {}\n",
    "\n",
    "# Use zip to iterate over matches and sections simultaneously\n",
    "for match, section in zip(matches, sections):\n",
    "    section_title = match.strip()\n",
    "    content = section.strip()\n",
    "    section_contents[section_title] = content\n",
    "\n",
    "section_contents.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_contents[\"6 Conclusion\"] #TODO: process this to ONLY the abstract content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, content in section_contents.items():\n",
    "    print(title)\n",
    "    print(len(content))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsection = section_contents[\"3 Why Generalization Occurs: Representations and Dynamics\"]\n",
    "subsection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then extract subsections from sections\n",
    "pattern = r\"\\n\\d+\\.\\d+ [A-Z][a-zA-Z\\s:]+\\n\"\n",
    "\n",
    "subsections = re.findall(pattern, subsection)\n",
    "print(len(subsections))\n",
    "for match in subsections:\n",
    "    print(match.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe aim to understand grokking , a phenomenon where models generalize long after\\noverﬁtting their training set. We present both a microscopic analysis anchored by an\\neffective theory and a macroscopic analysis of phase diagrams describing learning\\nperformance across hyperparameters. We ﬁnd that generalization originates from\\nstructured representations whose training dynamics and dependence on training set\\nsize can be predicted by our effective theory in a toy setting. We observe empirically\\nthe presence of four learning phases: comprehension ,grokking ,memorization , and\\nconfusion . We ﬁnd representation learning to occur only in a “Goldilocks zone”\\n(including comprehension and grokking) between memorization and confusion.\\nWe ﬁnd on transformers the grokking phase stays closer to the memorization phase\\n(compared to the comprehension phase), leading to delayed generalization. The\\nGoldilocks phase is reminiscent of “intelligence from starvation” in Darwinian\\nevolution, where resource limitations drive discovery of more efﬁcient solutions.\\nThis study not only provides intuitive explanations of the origin of grokking, but\\nalso highlights the usefulness of physics-inspired tools, e.g., effective theories and\\nphase diagrams, for understanding deep learning.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract references from conclusion\n",
    "abstract = section_contents[\"Abstract\"]\n",
    "section_contents[\"Abstract\"] = abstract.split(\"Abstract\")[1]\n",
    "\n",
    "section_contents[\"Abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract references from conclusion\n",
    "conclusion = section_contents[\"6 Conclusion\"]\n",
    "section_contents[\"6 Conclusion\"] = conclusion.split(\"References\")[0]\n",
    "# conclusion.split(\"References\")[1]\n",
    "\n",
    "section_contents[\"6 Conclusion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run subsection splitting algo\n",
    "\n",
    "for title, section in section_contents.items():\n",
    "  pattern = r\"\\n\\d+\\.\\d+ [A-Z][a-zA-Z\\s:]+\\n\"\n",
    "  subsections_headers = re.findall(pattern, section)\n",
    "  \n",
    "  if len(subsections_headers) > 0:\n",
    "    subsection_map = {}\n",
    "    subsections_content = re.split(pattern, section)\n",
    "\n",
    "    subsections_headers.insert(0, title)\n",
    "    for subsection_header, subsection in zip(subsections_headers, subsections_content):\n",
    "      subsection_title = subsection_header.strip()\n",
    "      content = subsection.strip()\n",
    "      subsection_map[subsection_title] = content\n",
    "\n",
    "    print(subsection_map.keys())\n",
    "    section_contents[title] = subsection_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(section_contents[\"3 Why Generalization Occurs: Representations and Dynamics\"])\n",
    "len(section_contents[\"4 Delayed Generalization: A Phase Diagram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this for section title-based splitting\n",
    "section_contents[\"4 Delayed Generalization: A Phase Diagram\"]['4.1 Phase diagram of a toy model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text, model=\"ada_gcal\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# df_bills['ada_v2'] = df_bills[\"text\"].apply(lambda x : generate_embeddings (x, model = 'text-embedding-ada-002'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "azure_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "                api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "                api_type=\"azure\",\n",
    "                api_version = \"2024-02-01\",\n",
    "                model_name=\"ada_gcal\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "# Example setup of the client to connect to your chroma server\n",
    "client = chromadb.HttpClient(host='localhost', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.delete_collection(name=\"test_pdf_2\") \n",
    "# Delete a collection and all associated embeddings, documents, and metadata. ⚠️ This is destructive and not reversible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(\n",
    "        embedding_function=azure_ef,\n",
    "        name=\"test_pdf_2\",\n",
    "        metadata={\"hnsw:space\": \"l2\"} # l2 is the default\n",
    "    )\n",
    "collection = client.get_collection(name=\"test_pdf_2\", embedding_function=azure_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': [],\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'data': None,\n",
       " 'uris': None}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.peek() # returns a list of the first 10 items in the collection\n",
    "# collection.count() # returns the number of items in the collection\n",
    "# collection.modify(name=\"new_name\") # Rename the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.add(\n",
    "#     documents=[\"lorem ipsum...\", \"doc2\", \"doc3\", ...],\n",
    "#     metadatas=[{\"chapter\": \"3\", \"verse\": \"16\"}, {\"chapter\": \"3\", \"verse\": \"5\"}, {\"chapter\": \"29\", \"verse\": \"11\"}, ...],\n",
    "#     ids=[\"id1\", \"id2\", \"id3\", ...]\n",
    "# )\n",
    "\n",
    "import uuid\n",
    "\n",
    "for title, content in section_contents.items():\n",
    "  unique_id = str(uuid.uuid4())\n",
    "  if type(content) == dict:\n",
    "    for t, c in content.items():\n",
    "      collection.add(\n",
    "      documents = [c],\n",
    "      metadatas=[{\"section_title\": t}],\n",
    "      ids=[unique_id]\n",
    "    )\n",
    "  else:\n",
    "    collection.add(\n",
    "      documents = [content],\n",
    "      metadatas=[{\"section_title\": title}],\n",
    "      ids=[unique_id]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiQueryPrompt = \"\"\"You are an AI language model assistant. Your task is to generate Five\n",
    "    different versions of the given user question to retrieve relevant documents from a vector\n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search.\n",
    "    Provide these alternative questions seperated by newlines only.\n",
    "\n",
    "    For example:\n",
    "    User question: \"What is the conclusion of the paper?\"\n",
    "\n",
    "    Generated questions:\n",
    "    What is the main takeaway from the paper?\n",
    "    What are the key findings of the paper?\n",
    "    What is the summary of the paper?\n",
    "    What is the final thought of the paper?\n",
    "    What is the ending of the paper?\n",
    "    \n",
    "    Output format should be as follows:\n",
    "\n",
    "    'What is Bill Gates known for?'\n",
    "│   \"Can you provide information about Bill Gates' background?\"\n",
    "\n",
    "    And not this format:\n",
    "\n",
    "    '1. What is Bill Gates known for?'\n",
    "│   \"2. Can you provide information about Bill Gates' background?\"\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9F8CPb7XKMd3GAlugZAiLwvaPwBFr\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"What is the reason behind generalization happening?\\nWhat causes generalization?\\nWhat are the principles responsible for generalization?\\nWhat triggers the occurrence of generalization?\\nWhat is the underlying mechanism causing generalization?\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1713393465,\n",
      "  \"model\": \"gpt-4-32k\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 40,\n",
      "    \"prompt_tokens\": 228,\n",
      "    \"total_tokens\": 268\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "What is the reason behind generalization happening?\n",
      "What causes generalization?\n",
      "What are the principles responsible for generalization?\n",
      "What triggers the occurrence of generalization?\n",
      "What is the underlying mechanism causing generalization?\n",
      "['What is the reason behind generalization happening?', 'What causes generalization?', 'What are the principles responsible for generalization?', 'What triggers the occurrence of generalization?', 'What is the underlying mechanism causing generalization?']\n"
     ]
    }
   ],
   "source": [
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version = \"2024-02-01\",\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"cursor-gpt-4\", # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": multiQueryPrompt},\n",
    "        {\"role\": \"user\", \"content\": \"why does generalization occur?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "questions = response.choices[0].message.content.split(\"\\n\")\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs = collection.query(\n",
    "    query_texts=questions,\n",
    "    n_results=1,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"},\n",
    "    # where_document={\"$contains\":\"search_string\"}\n",
    ")\n",
    "\n",
    "len(relevant_docs['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['502463a7-4688-4dd0-9d6f-9a54b0add4b7'],\n",
       "  ['502463a7-4688-4dd0-9d6f-9a54b0add4b7'],\n",
       "  ['db9b51c0-a91e-4d1a-8042-4f5e21d308d5'],\n",
       "  ['502463a7-4688-4dd0-9d6f-9a54b0add4b7'],\n",
       "  ['502463a7-4688-4dd0-9d6f-9a54b0add4b7']],\n",
       " 'distances': [[0.32639008158242083],\n",
       "  [0.34207177947302075],\n",
       "  [0.3684194708813717],\n",
       "  [0.3392694363749785],\n",
       "  [0.33198065226081047]],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [[{'section_title': '1 Introduction'}],\n",
       "  [{'section_title': '1 Introduction'}],\n",
       "  [{'section_title': '3 Why Generalization Occurs: Representations and Dynamics'}],\n",
       "  [{'section_title': '1 Introduction'}],\n",
       "  [{'section_title': '1 Introduction'}]],\n",
       " 'documents': [['Perhaps thecentral challenge of a scientiﬁc understanding of deep learning lies in accounting for neu-\\nral network generalization. Power et al. [ 1] recently added a new puzzle to the task of understanding\\ngeneralization with their discovery of grokking . Grokking refers to the surprising phenomenon of\\ndelayed generalization where neural networks, on certain learning problems, generalize long after\\noverﬁtting their training set. It is a rare albeit striking phenomenon that violates common machine\\nlearning intuitions, raising three key puzzles:\\nQ1The origin of generalization : When trained on the algorithmic datasets where grokking occurs,\\nhow do models generalize at all?\\nQ2The critical training size : Why does the training time needed to “grok” (generalize) diverge as\\nthe training set size decreases toward a critical point?\\nQ3Delayed generalization : Under what conditions does delayed generalization occur?\\nWe provide evidence that representation learning is central to answering each of these questions. Our\\nanswers can be summarized as follows:\\nA1Generalization can be attributed to learning a good representation of the input embeddings,\\ni.e., a representation that has the appropriate structure for the task and which can be predicted\\nfrom the theory in Section 3. See Figures 1 and 2.\\nA2The critical training set size corresponds to the least amount of training data that can determine\\nsuch a representation (which, in some cases, is unique up to linear transformations).\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2205.10343v2  [cs.LG]  14 Oct 2022Initialization (0 iterations)\\ntrain acc: 0.0 — val acc: 0.0Overﬁtting (1000 iterations)\\ntrain acc: 1.0 — val acc: 0.1Representation Learning (20000 iterations)\\ntrain acc: 1.0 — val acc: 1.0Figure 1: Visualization of the ﬁrst two principal components of the learned input embeddings at\\ndifferent training stages of a transformer learning modular addition. We observe that generalization\\ncoincides with the emergence of structure in the embeddings. See Section 4.2 for the training details.\\nA3Grokking is a phase between “comprehension” and “memorization” phases and it can be\\nremedied with proper hyperparmeter tuning, as illustrated by the phase diagrams in Figure 6.\\nThis paper is organized as follows: In Section 2, we introduce the problem setting and build a\\nsimpliﬁed toy model. In Section 3, we will use an effective theory approach, a useful tool from\\ntheoretical physics, to shed some light on questions Q1andQ2and show the relationship between\\ngeneralization and the learning of structured representations. In Section 4, we explain Q3by\\ndisplaying phase diagrams from a grid search of hyperparameters and show how we can “de-delay”\\ngeneralization by following intuition developed from the phase diagram. We discuss related work in\\nSection 5, followed by conclusions in Section 6.1'],\n",
       "  ['Perhaps thecentral challenge of a scientiﬁc understanding of deep learning lies in accounting for neu-\\nral network generalization. Power et al. [ 1] recently added a new puzzle to the task of understanding\\ngeneralization with their discovery of grokking . Grokking refers to the surprising phenomenon of\\ndelayed generalization where neural networks, on certain learning problems, generalize long after\\noverﬁtting their training set. It is a rare albeit striking phenomenon that violates common machine\\nlearning intuitions, raising three key puzzles:\\nQ1The origin of generalization : When trained on the algorithmic datasets where grokking occurs,\\nhow do models generalize at all?\\nQ2The critical training size : Why does the training time needed to “grok” (generalize) diverge as\\nthe training set size decreases toward a critical point?\\nQ3Delayed generalization : Under what conditions does delayed generalization occur?\\nWe provide evidence that representation learning is central to answering each of these questions. Our\\nanswers can be summarized as follows:\\nA1Generalization can be attributed to learning a good representation of the input embeddings,\\ni.e., a representation that has the appropriate structure for the task and which can be predicted\\nfrom the theory in Section 3. See Figures 1 and 2.\\nA2The critical training set size corresponds to the least amount of training data that can determine\\nsuch a representation (which, in some cases, is unique up to linear transformations).\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2205.10343v2  [cs.LG]  14 Oct 2022Initialization (0 iterations)\\ntrain acc: 0.0 — val acc: 0.0Overﬁtting (1000 iterations)\\ntrain acc: 1.0 — val acc: 0.1Representation Learning (20000 iterations)\\ntrain acc: 1.0 — val acc: 1.0Figure 1: Visualization of the ﬁrst two principal components of the learned input embeddings at\\ndifferent training stages of a transformer learning modular addition. We observe that generalization\\ncoincides with the emergence of structure in the embeddings. See Section 4.2 for the training details.\\nA3Grokking is a phase between “comprehension” and “memorization” phases and it can be\\nremedied with proper hyperparmeter tuning, as illustrated by the phase diagrams in Figure 6.\\nThis paper is organized as follows: In Section 2, we introduce the problem setting and build a\\nsimpliﬁed toy model. In Section 3, we will use an effective theory approach, a useful tool from\\ntheoretical physics, to shed some light on questions Q1andQ2and show the relationship between\\ngeneralization and the learning of structured representations. In Section 4, we explain Q3by\\ndisplaying phase diagrams from a grid search of hyperparameters and show how we can “de-delay”\\ngeneralization by following intuition developed from the phase diagram. We discuss related work in\\nSection 5, followed by conclusions in Section 6.1'],\n",
       "  ['We can see that generalization appears to be linked to the emergence of highly-structured embeddings\\nin Figure 2. In particular, Figure 2 (a, b) shows parallelograms in toy addition, and (c, d) shows a\\ncircle in toy modular addition. We now restrict ourselves to the toy addition setup and formalize a\\nnotion of representation quality and show that it predicts the model’s performance. We then develop a\\nphysics-inspired effective theory of learning which can accurately predict the critical training set size\\nand training trajectories of representations. The concept of an effective theory in physics is similar\\nto model reduction in computational methods in that it aims to describe complex phenomena with\\nsimple yet intuitive pictures. In our effective theory, we will model the dynamics of representation\\nlearning not as gradient descent of the true task loss but rather a simpler effective loss function ℓeff\\nwhich depends only on the representations in embedding space and not on the decoder.'],\n",
       "  ['Perhaps thecentral challenge of a scientiﬁc understanding of deep learning lies in accounting for neu-\\nral network generalization. Power et al. [ 1] recently added a new puzzle to the task of understanding\\ngeneralization with their discovery of grokking . Grokking refers to the surprising phenomenon of\\ndelayed generalization where neural networks, on certain learning problems, generalize long after\\noverﬁtting their training set. It is a rare albeit striking phenomenon that violates common machine\\nlearning intuitions, raising three key puzzles:\\nQ1The origin of generalization : When trained on the algorithmic datasets where grokking occurs,\\nhow do models generalize at all?\\nQ2The critical training size : Why does the training time needed to “grok” (generalize) diverge as\\nthe training set size decreases toward a critical point?\\nQ3Delayed generalization : Under what conditions does delayed generalization occur?\\nWe provide evidence that representation learning is central to answering each of these questions. Our\\nanswers can be summarized as follows:\\nA1Generalization can be attributed to learning a good representation of the input embeddings,\\ni.e., a representation that has the appropriate structure for the task and which can be predicted\\nfrom the theory in Section 3. See Figures 1 and 2.\\nA2The critical training set size corresponds to the least amount of training data that can determine\\nsuch a representation (which, in some cases, is unique up to linear transformations).\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2205.10343v2  [cs.LG]  14 Oct 2022Initialization (0 iterations)\\ntrain acc: 0.0 — val acc: 0.0Overﬁtting (1000 iterations)\\ntrain acc: 1.0 — val acc: 0.1Representation Learning (20000 iterations)\\ntrain acc: 1.0 — val acc: 1.0Figure 1: Visualization of the ﬁrst two principal components of the learned input embeddings at\\ndifferent training stages of a transformer learning modular addition. We observe that generalization\\ncoincides with the emergence of structure in the embeddings. See Section 4.2 for the training details.\\nA3Grokking is a phase between “comprehension” and “memorization” phases and it can be\\nremedied with proper hyperparmeter tuning, as illustrated by the phase diagrams in Figure 6.\\nThis paper is organized as follows: In Section 2, we introduce the problem setting and build a\\nsimpliﬁed toy model. In Section 3, we will use an effective theory approach, a useful tool from\\ntheoretical physics, to shed some light on questions Q1andQ2and show the relationship between\\ngeneralization and the learning of structured representations. In Section 4, we explain Q3by\\ndisplaying phase diagrams from a grid search of hyperparameters and show how we can “de-delay”\\ngeneralization by following intuition developed from the phase diagram. We discuss related work in\\nSection 5, followed by conclusions in Section 6.1'],\n",
       "  ['Perhaps thecentral challenge of a scientiﬁc understanding of deep learning lies in accounting for neu-\\nral network generalization. Power et al. [ 1] recently added a new puzzle to the task of understanding\\ngeneralization with their discovery of grokking . Grokking refers to the surprising phenomenon of\\ndelayed generalization where neural networks, on certain learning problems, generalize long after\\noverﬁtting their training set. It is a rare albeit striking phenomenon that violates common machine\\nlearning intuitions, raising three key puzzles:\\nQ1The origin of generalization : When trained on the algorithmic datasets where grokking occurs,\\nhow do models generalize at all?\\nQ2The critical training size : Why does the training time needed to “grok” (generalize) diverge as\\nthe training set size decreases toward a critical point?\\nQ3Delayed generalization : Under what conditions does delayed generalization occur?\\nWe provide evidence that representation learning is central to answering each of these questions. Our\\nanswers can be summarized as follows:\\nA1Generalization can be attributed to learning a good representation of the input embeddings,\\ni.e., a representation that has the appropriate structure for the task and which can be predicted\\nfrom the theory in Section 3. See Figures 1 and 2.\\nA2The critical training set size corresponds to the least amount of training data that can determine\\nsuch a representation (which, in some cases, is unique up to linear transformations).\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2205.10343v2  [cs.LG]  14 Oct 2022Initialization (0 iterations)\\ntrain acc: 0.0 — val acc: 0.0Overﬁtting (1000 iterations)\\ntrain acc: 1.0 — val acc: 0.1Representation Learning (20000 iterations)\\ntrain acc: 1.0 — val acc: 1.0Figure 1: Visualization of the ﬁrst two principal components of the learned input embeddings at\\ndifferent training stages of a transformer learning modular addition. We observe that generalization\\ncoincides with the emergence of structure in the embeddings. See Section 4.2 for the training details.\\nA3Grokking is a phase between “comprehension” and “memorization” phases and it can be\\nremedied with proper hyperparmeter tuning, as illustrated by the phase diagrams in Figure 6.\\nThis paper is organized as follows: In Section 2, we introduce the problem setting and build a\\nsimpliﬁed toy model. In Section 3, we will use an effective theory approach, a useful tool from\\ntheoretical physics, to shed some light on questions Q1andQ2and show the relationship between\\ngeneralization and the learning of structured representations. In Section 4, we explain Q3by\\ndisplaying phase diagrams from a grid search of hyperparameters and show how we can “de-delay”\\ngeneralization by following intuition developed from the phase diagram. We discuss related work in\\nSection 5, followed by conclusions in Section 6.1']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provided_context = relevant_docs\n",
    "provided_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplate:\n",
    "    def __init__(self, input_variables, template):\n",
    "        self.input_variables = input_variables\n",
    "        self.template = template\n",
    "\n",
    "    def format(self, **kwargs):\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qaPrompt = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "#     \\n --- \\n {query_str} \\n --- \\n\n",
    "\n",
    "#     Here is any available background question + answer pairs:\n",
    "\n",
    "#     \\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "#     Here is additional context relevant to the question:\n",
    "\n",
    "#     \\n --- \\n {context_str} \\n --- \\n\n",
    "\n",
    "#     Use the above context and any background question + answer pairs to answer the question: \\n {query_str}\n",
    "#     \"\"\"\n",
    "\n",
    "# TODO: q_a_pairs from FT-ed model\n",
    "\n",
    "qaPrompt = \"\"\"\n",
    "Your task is to use the document excerpts to provide answers. \n",
    "Answer questions precisely and succinctly but provide full lists of steps and stipulations if the response requires it.\n",
    "If you cannot provide answers based on the context provided, answer with \"I cannot answer the question based on the context provided\".\n",
    "\n",
    "Answer questions with as much detail as possible. Think logically and take it step by step. If the content explains where to find more information, please include that in your answer.\n",
    "\n",
    "DO NOT provide information other than what you have in the CONTENT.\n",
    "Do NOT mention \"the document\" or \"the context\" in your answer.\n",
    "\n",
    "Here is the document relevant to the question:\n",
    "\n",
    "    ###{context_str}###\n",
    "\n",
    "Do not create new context or use external sources to provide answers. Use only the context provided to answer the question.\n",
    "    \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"context_str\"], template=qaPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your task is to use the document excerpts to provide answers. \n",
      "Answer questions precisely and succinctly but provide full lists of steps and stipulations if the response requires it.\n",
      "If you cannot provide answers based on the context provided, answer with \"I cannot answer the question based on the context provided\".\n",
      "\n",
      "Answer questions with as much detail as possible. Think logically and take it step by step. If the content explains where to find more information, please include that in your answer.\n",
      "\n",
      "DO NOT provide information other than what you have in the CONTENT.\n",
      "Do NOT mention \"the document\" or \"the context\" in your answer.\n",
      "\n",
      "Here is the document relevant to the question:\n",
      "\n",
      "    ###only PyPDF library can be used to access Large Language Models###\n",
      "\n",
      "Do not create new context or use external sources to provide answers. Use only the context provided to answer the question.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = prompt_template.format(context_str=\"only PyPDF library can be used to access Large Language Models\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9FCZ3o1GaFN8nJl5bQi1XhvbP1rM4\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Only the PyPDF library can be used to access Large Language Models.\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1713410245,\n",
      "  \"model\": \"gpt-4-32k\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 14,\n",
      "    \"prompt_tokens\": 194,\n",
      "    \"total_tokens\": 208\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Only the PyPDF library can be used to access Large Language Models.\n"
     ]
    }
   ],
   "source": [
    "uesr_query = \"What libraries can be used to via Large Language Models?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"cursor-gpt-4\", # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": formatted_prompt},\n",
    "        {\"role\": \"user\", \"content\": uesr_query}\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
