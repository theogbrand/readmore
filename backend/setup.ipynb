{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../creds/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "azure_endpoint = \"https://cursor-gpt-4.openai.azure.com\"\n",
    "api_version=\"2024-02-15-preview\"\n",
    "\n",
    "\n",
    "cliient = AzureOpenAI(\n",
    "        azure_endpoint=azure_endpoint,\n",
    "        api_version=api_version,\n",
    "    )\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You're an AI assistant designed to help users return current weather. When a user asks for the weather in a given location, you should call the get_current_weather function. Don't make assumptions about what values to use with functions. Ask for clarification if a user request is ambiguous. Only use the functions you have been provided with.\"}, {\"role\": \"user\", \"content\": \"who is Jeff Dean?\"} # What's the weather like in San Francisco, Tokyo, and Paris?\n",
    "]\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        # mode details the better in desc\n",
    "                        # \"description\": \"The location of the hotel. The location should include the city and the state's abbreviation (i.e. Seattle, WA or Miami, FL)\"\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"pjf-dpo-turbo-35\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, or none\n",
    "    seed=42,\n",
    "    temperature=0,\n",
    "    max_tokens =200, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pinecone-client\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key='YOUR_API_KEY')\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc.create_index(\n",
    "    name=\"quickstart\",\n",
    "    dimension=8,\n",
    "    metric=\"euclidean\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud='aws', \n",
    "        region='us-east-1'\n",
    "    ) \n",
    ") \n",
    "\n",
    "index = pc.Index(\"quickstart\")\n",
    "index.upsert(\n",
    "    vectors=[\n",
    "        {\"id\": \"vec1\", \"values\": [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]},\n",
    "        {\"id\": \"vec2\", \"values\": [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]},\n",
    "        {\"id\": \"vec3\", \"values\": [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3]},\n",
    "        {\"id\": \"vec4\", \"values\": [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4]}\n",
    "    ],\n",
    "    namespace=\"ns1\"\n",
    ")\n",
    "\n",
    "index.upsert(\n",
    "    vectors=[\n",
    "        {\"id\": \"vec5\", \"values\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]},\n",
    "        {\"id\": \"vec6\", \"values\": [0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6]},\n",
    "        {\"id\": \"vec7\", \"values\": [0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7]},\n",
    "        {\"id\": \"vec8\", \"values\": [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]}\n",
    "    ],\n",
    "    namespace=\"ns2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()\n",
    "\n",
    "# Returns:\n",
    "# {'dimension': 8,\n",
    "#  'index_fullness': 0.0,\n",
    "#  'namespaces': {'ns1': {'vector_count': 4}, 'ns2': {'vector_count': 4}},\n",
    "#  'total_vector_count': 8}\n",
    "\n",
    "index.query(\n",
    "    namespace=\"ns1\",\n",
    "    vector=[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
    "    top_k=3,\n",
    "    include_values=True\n",
    ")\n",
    "\n",
    "index.query(\n",
    "    namespace=\"ns2\",\n",
    "    vector=[0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7],\n",
    "    top_k=3,\n",
    "    include_values=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc.delete_index(\"quickstart\")\n",
    "\n",
    "# export PINECONE_API_KEY=<YOUR_API_KEY>\n",
    "# export INDEX_HOST=pdf-ai-do8rm7p.svc.apw5-4e34-81fa.pinecone.io\n",
    "\n",
    "# curl -X POST \"https://$INDEX_HOST/vectors/delete\" \\\n",
    "#   -H \"Api-Key: $PINECONE_API_KEY\" \\\n",
    "#   -H 'Content-Type: application/json' \\\n",
    "#   -d '{\n",
    "#     \"deleteAll\": true,\n",
    "#     \"namespace\": \"clugy1k2b0000xxk54xtc7bmy\"\n",
    "#   }\n",
    "# '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"ada_gcal\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "azure_endpoint = \"https://cursor-gpt-4.openai.azure.com\"\n",
    "api_version=\"2024-02-15-preview\"\n",
    "\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"pjf-dpo-turbo-35\", # model = \"deployment_name\"\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "response = llm.complete(\"Paul Graham is \")\n",
    "print(response)\n",
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
